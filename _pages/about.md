---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


<h1 id="aboutme"> About me </h1>

I am a PhD Student at Jagiellonian Univeristy in Kraków, Poland. I am working in the Group for Machine Learning Research ([GMUM](https://gmum.net/)) led by prof. Jacek Tabor. My main research interests is the analysis and development of sparse neural networks. In particular, I focus on advancing tools that allow the network to change and adapt already during the training.   



<h1 id="news"> News </h1>

- <span style="color:#D58A94">**(May 2024)**</span> Our work, [*Sparser, Better, Deeper, Stronger: Improving Sparse Training with Exact Orthogonal Initialization*](https://icml.cc/virtual/2024/poster/32889) has been accepted to **ICML 2024**! See in Vienna and many thanks to co-authors!
- <span style="color:#D58A94">**(December 2023)**</span> At **NeuRIPS 2023** presenting two of my papers,  [*Trust Your ∇ : Gradient-based Intervention Targeting for Causal Discovery*](https://arxiv.org/abs/2211.13715) and [*Fantastic Weights and How to Find Them: Where to Prune in Dynamic Sparse Training*](https://arxiv.org/abs/2306.12230)! Be sure to drop by at the poster session! 
- <span style="color:#D58A94">**(October 2023)**</span> Super excited to start my internship as Student Researcher in **Google DeepMind in Montreal**, where I will be workig on efficeint adaptation in transfer learning! 
- <span style="color:#D58A94">**(May 2023)**</span> See you at the  [ICLR23 SNN Workshop](https://www.sparseneural.net/organizers)  in Kigali, Rwanda! Many thanks to all other organizers!
- <span style="color:#D58A94">**(January 2023)**</span> I am joining [IDEAS NCBR](https://ideas-ncbr.pl/en/) as Student PhD Researcher working on efficient deep neural networks and sparse architectures.   
- <span style="color:#D58A94">**(September 2022)**</span> Starting a research internship at Univeristy of Twente, Netherlands in the VScAIL group led by dr. Decebal Mocanu.
- <span style="color:#D58A94">**(July 2022)**</span> Presenting  our work, [*Connectivity Properties of Neural Networks Under Performance-Resources Trade-off*](https://dynn-icml2022.github.io/papers/paper_24.pdf) at the Dynamic Neural Networks, ICML 2022 Workshop.
- <span style="color:#D58A94">**(July 2022)**</span> The [MLSS^N](https://mlss.mlinpl.org/) school if finally here! Thanks to all other organizers and volunteers for the enormous work and passion put into making the event possible.  The lectures are available [here](https://www.youtube.com/playlist?list=PL3aJIq_dM1xUpQxVgP4AySZAJtdVx-2qI).
- <span style="color:#D58A94">**(June 2022)**</span> Two my papers, *Discovering wiring patterns influencing neural networks performance* and *On the relationship between disentanglement and
multi-task learning* have been accepted to ECML PKDD 2022.
- <span style="color:#D58A94">**(April 2022)**</span> I presented our work on analyzing neural network architectures based on random graphs at the 
meeting *[From Neuroscience to Artificially Intelligent Systems (NAISys)](https://meetings.cshl.edu/abstracts.aspx?meet=NAISYS&year=22)* in Cold Spring Harbor Laboratory (CSHL), USA.
- <span style="color:#D58A94">**(November 2021)**</span> - Co-organized the [ML in PL Conference 2021](https://conference2021.mlinpl.org).
- <span style="color:#D58A94">**(November 2021)**</span> - I've participated in the *Google Women in Tech Mentoring Program* (online), together with 31 selected students across Poland.
- <span style="color:#D58A94">**(September 2021)**</span> Our work *Non-Gaussian Gaussian Processes for Few Shot Regression* has been accepted to NeurIPS 2021.
- <span style="color:#D58A94">**(July 2020)**</span> Co-organizing the Eastern European Machine Learning Summer School 2020 ([ECML 2020](https://www.eeml.eu/previous-editions/eeml2020)).
- <span style="color:#D58A94">**(December 2019)**</span> Presenting our work on *Non-linear ICA based on
Cramer-Wold metric* on ICONIP in Sydney, Australia. 
- <span style="color:#D58A94">**(November 2019)**</span> Co-conducting workshops in reinforcement learning at the [MLinPL](https://conference.mlinpl.org/) conference.
- <span style="color:#D58A94">**(October 2019)**</span> I've started my PhD studies at Jagiellonian Univeristy in Kraków, Poland.



<h1 id="publications"> Selected Publications </h1>

<div style="margin-bottom: 1em">
    <img src="/images/givens.png" alt="The Exact Orthogonal Initialization Scheme" style="width: 29%; display: inline-block; vertical-align: middle; padding: 5px">
    <div style="display: inline-block; padding: 10px; vertical-align: middle; width: 69%">
        <strong style="color:#D58A94">Sparser, Better, Deeper, Stronger: Improving Sparse Training with Exact Orthogonal Initialization</strong> <br/>
        Aleksandra Nowak, Łukasz Gniecki, Filip Szatkowski, Jacek Tabor <br/>
        <b>ICML 2024</b> <br/>
        <a href="https://icml.cc/virtual/2024/poster/32889">[Paper]</a>
    </div>
</div>

<div style="margin-bottom: 1em">
    <img src="/images/performance.png" alt="The DST performance with respect to pruning criterion" style="width: 29%; display: inline-block; vertical-align: middle; padding: 5px">
    <div style="display: inline-block; padding: 10px; vertical-align: middle; width: 69%">
        <strong style="color:#D58A94">Fantastic Weights and How to Find Them: Where to Prune in Dynamic Sparse Training</strong> <br/>
        Aleksandra Nowak, Bram Grooten, Decebal C. Mocanu, Jacek Tabor <br/>
        <b>NeurIPS 2023</b> <br/>
        <a href="https://arxiv.org/abs/2306.12230">[Paper]</a>
    </div>
</div>

<div style="margin-bottom: 1em">
    <img src="/images/trust.png" alt="The GIT Scheme" style="width: 29%; display: inline-block; vertical-align: middle; padding: 5px">
    <div style="display: inline-block; padding: 10px; vertical-align: middle; width: 69%">
        <strong style="color:#D58A94"> Trust Your ∇ : Gradient-based Intervention Targeting for Causal Discovery</strong> <br/>
        Mateusz Olko*, Michał Zając*, Aleksandra Nowak*, Nino Scherrer, Yashas Annadani, Stefan Bauer, Łukasz Kuciński, Piotr Miłoś <br/>
        <b>NeurIPS 2023</b> <br/>
        <a href="https://arxiv.org/abs/2211.13715">[Paper]</a>
    </div>
</div>

<div style="margin-bottom: 1em">
    <img src="/images/all_top.png" alt="Top Random Architectures" style="width: 29%; display: inline-block; vertical-align: middle; padding: 5px">
    <div style="display: inline-block; padding: 10px; vertical-align: middle; width: 69%">
        <strong style="color:#D58A94">Discovering wiring patterns influencing neural networks performance</strong> <br/>
        Aleksandra Nowak, Romuald Janik <br/>
        <b>ECML PKDD 2022</b> <br/>
        <a href="https://2022.ecmlpkdd.org/wp-content/uploads/2022/09/sub_1358.pdf">[Paper]</a>
    </div>
</div>

<div style="margin-bottom: 1em">
    <img src="/images/gnaw.png" alt="Pruned Network" style="width: 29%; display: inline-block; vertical-align: middle; padding: 5px">
    <div style="display: inline-block; padding: 10px; vertical-align: middle; width: 69%">
        <strong style="color:#D58A94">Neural Networks Adapting to Datasets: Learning Network Size and Topology</strong> <br/>
        Romuald Janik, Aleksandra Nowak <br/>
        <b>Dynamic Neural Networks, ICML 2022 Workshop</b> <br/>
        <a href="https://arxiv.org/abs/2006.12195">[Paper]</a>
    </div>
</div>

<div style="margin-bottom: 1em">
    <img src="/images/NGGP.png" alt="The NGGP scheme" style="width: 29%; display: inline-block; vertical-align: middle; padding: 5px">
    <div style="display: inline-block; padding: 10px; vertical-align: middle; width: 69%">
        <strong style="color:#D58A94">Non-Gaussian Gaussian Processes for Few Shot Regression</strong> <br/>
        Marcin Sendera, Jacek Tabor, Aleksandra Nowak, Andrzej Bedychaj, Massimiliano Patacchiola, Tomasz Trzcinski, Przemysław Spurek, Maciej Zieba <br/>
        <b>NeurIPS 2021</b> <br/>
        <a href="https://arxiv.org/abs/2110.13561">[Paper]</a>
    </div>
</div>








